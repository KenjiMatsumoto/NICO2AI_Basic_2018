{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"nico2ai_lecture11_exercise.ipynb","version":"0.3.2","views":{},"default_view":{},"provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"metadata":{"id":"Vw0ugIyic_MQ","colab_type":"text"},"cell_type":"markdown","source":["# NICO2AI Lecture11 Reinforcement Learning I Exercise\n","\n","## OpenAI Gym\n","- website https://gym.openai.com/\n","\n","OpenAI GymはOpenAIより提供されているAI向けの学習環境です．たくさんのタスクが提供されています．[ここ](https://gym.openai.com/envs)から環境一覧を見ることができます．\n","\n","### 多腕バンディット\n","OpenAI Gymは有志によるタスクの追加が可能になっています．ここではサードパーティより提供されている多腕バンディットの環境を使用します．この環境の強化学習設定は\n","\n","- 状態: なし（毎回同じ）\n","- 報酬: 確率的な当たり (0/1)\n","- 行動: バンディット番号(1~10)\n","- 価値: 当たる確率\n","\n","となっています．それでは必要なパッケージをインストールしましょう．"]},{"metadata":{"id":"dmc_xCYafWDc","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"output_extras":[{}],"base_uri":"https://localhost:8080/","height":644},"outputId":"b12b24ac-8412-4c02-9859-3b9c57cbc385","executionInfo":{"status":"ok","timestamp":1520562652527,"user_tz":-540,"elapsed":11115,"user":{"displayName":"妹尾卓磨","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"106933646678072983709"}}},"cell_type":"code","source":["!pip install gym\n","!pip install git+https://github.com/JKCooper2/gym-bandits"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Collecting gym\n","  Downloading gym-0.10.3.tar.gz (1.5MB)\n","\u001b[K    100% |████████████████████████████████| 1.5MB 766kB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.6/dist-packages (from gym)\n","Collecting pyglet>=1.2.0 (from gym)\n","  Downloading pyglet-1.3.1-py2.py3-none-any.whl (1.0MB)\n","\u001b[K    100% |████████████████████████████████| 1.0MB 1.1MB/s \n","\u001b[?25hRequirement already satisfied: requests>=2.0 in /usr/local/lib/python3.6/dist-packages (from gym)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from gym)\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet>=1.2.0->gym)\n","Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym)\n","Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym)\n","Building wheels for collected packages: gym\n","  Running setup.py bdist_wheel for gym ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \bdone\n","\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/5a/a6/d0/05104a8eb420874ede45834e89904141dc8a056a7193beb1a6\n","Successfully built gym\n","Installing collected packages: pyglet, gym\n","Successfully installed gym-0.10.3 pyglet-1.3.1\n","Collecting git+https://github.com/JKCooper2/gym-bandits\n","  Cloning https://github.com/JKCooper2/gym-bandits to /tmp/pip-mghy_cup-build\n","Requirement already satisfied: gym>=0.2.3 in /usr/local/lib/python3.6/dist-packages (from gym-bandits==0.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from gym>=0.2.3->gym-bandits==0.1)\n","Requirement already satisfied: requests>=2.0 in /usr/local/lib/python3.6/dist-packages (from gym>=0.2.3->gym-bandits==0.1)\n","Requirement already satisfied: pyglet>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym>=0.2.3->gym-bandits==0.1)\n","Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.6/dist-packages (from gym>=0.2.3->gym-bandits==0.1)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym>=0.2.3->gym-bandits==0.1)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym>=0.2.3->gym-bandits==0.1)\n","Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym>=0.2.3->gym-bandits==0.1)\n","Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym>=0.2.3->gym-bandits==0.1)\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet>=1.2.0->gym>=0.2.3->gym-bandits==0.1)\n","Installing collected packages: gym-bandits\n","  Running setup.py install for gym-bandits ... \u001b[?25l-\b \bdone\n","\u001b[?25hSuccessfully installed gym-bandits-0.1\n"],"name":"stdout"}]},{"metadata":{"id":"ElQtOYpQf-FK","colab_type":"text"},"cell_type":"markdown","source":["これで必要なパッケージが揃いました．次はいよいよ環境の作成を行います．"]},{"metadata":{"id":"h3e0HHe4fRE_","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["%matplotlib inline\n","import numpy as np\n","import gym\n","import gym_bandits\n","import random\n","import matplotlib.pyplot as plt\n","from IPython.display import display, clear_output\n","\n","env = gym.make(\"BanditTenArmedRandomFixed-v0\")"],"execution_count":0,"outputs":[]},{"metadata":{"id":"EGO5lr9FgLwk","colab_type":"text"},"cell_type":"markdown","source":["`gym.make('environment')`を実行することで環境のインスタンスを作成することができます．このインスタンスは次の関数を持ちます．\n","\n","### env.reset()\n","環境を初期化する．\n","\n","**return**\n","- state: 状態を表す配列\n","\n","### env.step(action)\n","整数値または連続値の配列`action`を実行して次の状態へ遷移する．\n","\n","**return**\n","\n","- state: 状態を表す配列\n","- reward: 浮動小数点または整数の報酬\n","- done: エピソードの終端を示すbool型の値\n","- info: 辞書型で表されたデバッグ情報\n","\n","これでバンディットの世界に入る準備ができました．最初のエクササイズとしてブランクのコードを埋めてε-greedyでバンディットを引くエージェントを実装して，パラメータを変更することでどのように性能に影響するか調べて見ましょう．"]},{"metadata":{"id":"Dpg2J5P0iFR9","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["epsilon = 0.3\n","hit_count = 0\n","total_rates = []\n","data = []\n","# data for 10 bandits\n","for i in range(10):\n","    data.append({'hit': 0, 'count': 0})\n","\n","def choose_action(data):\n","    # code here\n","    \n","env.reset()\n","for i in range(1000):\n","    action = choose_action(data)\n","    _, reward, _, _ = env.step(action)\n","    data[action]['hit'] += reward\n","    data[action]['count'] += 1\n","    hit_count += reward\n","    total_rates.append(float(hit_count) / (i + 1))\n","\n","plt.plot(np.arange(1000), np.array(total_rates))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"glzLG0PMjF1I","colab_type":"text"},"cell_type":"markdown","source":["やりましたね！これで最初の単純な強化学習エージェントを実装できました．では次にsoftmax探索を行うエージェントを実装して見ましょう．"]},{"metadata":{"id":"NUe5lMhRfJGA","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["hit_count = 0\n","tau = 1.0\n","total_rates = []\n","data = []\n","for i in range(10):\n","    data.append({'hit': 0, 'count': 0})\n","\n","def choose_action(data):\n","    # code here\n","    \n","env.reset()\n","for i in range(1000):\n","    action = choose_action(data)\n","    _, reward, _, _ = env.step(action)\n","    data[action]['hit'] += reward\n","    data[action]['count'] += 1\n","    hit_count += reward\n","    total_rates.append(float(hit_count) / (i + 1))\n","\n","plt.plot(np.arange(1000), np.array(total_rates))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"bGlCox8cjEEW","colab_type":"text"},"cell_type":"markdown","source":["では最後にUCB1探索を行うエージェントを実装して見ましょう！"]},{"metadata":{"id":"v0eksKMRjzYF","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["\n","hit_count = 0\n","total_rates = []\n","data = []\n","for i in range(10):\n","    data.append({'hit': 0, 'count': 0})\n","\n","def choose_action(data):\n","    # code here\n","    \n","env.reset()\n","for i in range(1000):\n","    action = choose_action(data)\n","    _, reward, _, _ = env.step(action)\n","    data[action]['hit'] += reward\n","    data[action]['count'] += 1\n","    hit_count += reward\n","    total_rates.append(float(hit_count) / (i + 1))\n","\n","plt.plot(np.arange(1000), np.array(total_rates))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"8tot4YkGpOlF","colab_type":"text"},"cell_type":"markdown","source":["おめでとうございます！これでエクササイズ11を修了しました！"]}]}